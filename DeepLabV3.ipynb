{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9PIDYuSGxDKH0dJ3aUGja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nerikoutchala/Nerikoutchala/blob/main/DeepLabV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Base Model configurations of the Ocelot Paper: DeepLabV3+**"
      ],
      "metadata": {
        "id": "ahFkdaY3NS1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load and Prepare Data and transform**"
      ],
      "metadata": {
        "id": "80n5xQ12Nldj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o33sbWhfaxZ",
        "outputId": "633dc633-ec97-478e-96d7-5e854f8d9618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai\n",
        "!pip install segmentation_models_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SClSzMdvOBBf",
        "outputId": "71e11a67-07ec-4ba4-a1ef-fab36d736a88"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: monai in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.15.2+cu118)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.4)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.1)\n",
            "Requirement already satisfied: timm==0.9.2 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.16.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models.segmentation import DeepLabV3\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "import monai.transforms as T\n",
        "import random\n",
        "from monai.transforms.compose import Randomizable\n",
        "\n",
        "\n",
        "import monai\n",
        "from monai.data import Dataset, DataLoader\n",
        "from monai.losses import DiceLoss\n",
        "from monai.metrics import DiceMetric\n",
        "\n",
        "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, Resized, RandRotated, \\\n",
        "    ScaleIntensityd, EnsureTyped, RandBiasFieldd, RandAdjustContrastd, \\\n",
        "    AsDiscreted, ToTensord, Rand2DElasticd, RandSpatialCropd, RandRotate90d, RandFlipd"
      ],
      "metadata": {
        "id": "KOshc3-KN4PO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_files_dir = \"/content/drive/MyDrive/ocelot/{}/train/tissue\"\n",
        "test_files_dir = \"/content/drive/MyDrive/ocelot/{}/test/tissue\"\n",
        "\n",
        "# tissues is a list of filenames\n",
        "tissues = list(sorted(glob.iglob(os.path.join(train_files_dir.format('images'), '*.jpg'))))\n",
        "masks = list(sorted(glob.iglob(os.path.join(train_files_dir.format('annotations'), '*.png'))))\n",
        "\n",
        "# Load train, test, and validation filenames and masks\n",
        "tissues = list(sorted(glob.iglob(os.path.join(train_files_dir.format('images'), '*.jpg'))))\n",
        "masks = list(sorted(glob.iglob(os.path.join(train_files_dir.format('annotations'), '*.png'))))\n",
        "\n",
        "test_tissues = list(sorted(glob.iglob(os.path.join(test_files_dir.format('images'), '*.jpg'))))\n",
        "test_masks = list(sorted(glob.iglob(os.path.join(test_files_dir.format('annotations'), '*.png'))))\n",
        "\n",
        "# Create dictionaries for training, testing, and validation data\n",
        "train_files_dict = [{\"img\": img, \"seg\": seg} for img, seg in zip(tissues, masks)]\n",
        "test_files_dict = [{\"img\": img, \"seg\": seg} for img, seg in zip(test_tissues, test_masks)]\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_files_dict, val_files_dict = train_test_split(train_files_dict, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Let's define the transformations to be applied to the images\n",
        "k = [\"img\", \"seg\"]\n",
        "num_classes = 3 # 3 classes: background, cancer, unknown\n",
        "spatial_size = (256, 256)\n",
        "\n",
        "# Custom transform to convert segmentation classes 1,2,255 into 0,1,2\n",
        "class TransformAnnot(monai.transforms.Transform):\n",
        "    'Output selected slice from input volume.'\n",
        "    def __call__(self, mk):\n",
        "        mk[mk==255] = 0\n",
        "        return mk\n",
        "\n",
        "class TransformAnnotd(monai.transforms.Transform):\n",
        "    'Output selected slice from input volume.'\n",
        "    def __init__(self, keys):\n",
        "        self.backend = TransformAnnot()\n",
        "        self.keys = keys\n",
        "\n",
        "    def __call__(self, data):\n",
        "        d = dict(data)\n",
        "        for k in d.keys():\n",
        "            if k not in self.keys:\n",
        "                continue\n",
        "            d[k] = self.backend.__call__(d[k])\n",
        "\n",
        "        return d\n",
        "\n",
        "\n",
        "seg_transforms = [\n",
        "    LoadImaged(keys=k),\n",
        "    TransformAnnotd(keys=['seg']),\n",
        "    EnsureChannelFirstd(keys=k),\n",
        "    ScaleIntensityd(keys=[\"img\"]),\n",
        "    ToTensord(keys=k),\n",
        "    AsDiscreted(keys=[\"seg\"], rounding='torchrounding'),\n",
        "    AsDiscreted(keys=[\"seg\"], to_onehot=num_classes),\n",
        "    RandSpatialCropd(keys=k, roi_size=spatial_size, random_size=False),\n",
        "    EnsureTyped(keys=k),\n",
        "]\n",
        "\n",
        "transform = Compose(seg_transforms)\n",
        "\n",
        "# Create data loaders for train, test, and validation sets\n",
        "train_dset = Dataset(train_files_dict, transform=transform)\n",
        "train_dloader = DataLoader(train_dset, batch_size=4, shuffle=True)\n",
        "\n",
        "test_dset = Dataset(test_files_dict, transform=transform)\n",
        "test_dloader = DataLoader(test_dset, batch_size=4, shuffle=False)\n",
        "\n",
        "val_dset = Dataset(val_files_dict, transform=transform)\n",
        "val_dloader = DataLoader(val_dset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "Jekh6CTzOYHi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import GaussianBlurd, GaussianNoised, ColorJitterd, RandFlipd, RandRotate90d\n",
        "\n",
        "# Define the data augmentation transforms using torchvision\n",
        "photometric_transforms = [\n",
        "    T.GaussianBlur(kernel_size=(5, 5), sigma=(0.5, 1.0)),\n",
        "    T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
        "]\n",
        "\n",
        "geometric_transforms = [\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomRotation(degrees=[0, 90, 180, 270]),\n",
        "]\n",
        "\n",
        "# Combine photometric and geometric transformations\n",
        "augmentation_transforms = photometric_transforms + geometric_transforms\n",
        "\n",
        "\n",
        "#########\n",
        "\n",
        "# Define custom MONAI transforms\n",
        "class CustomGaussianBlur(monai.transforms.Transform):\n",
        "    def __call__(self, data):\n",
        "        return {\"img\": custom_gaussian_blur(data[\"img\"])}\n",
        "\n",
        "class CustomGaussianNoise(monai.transforms.Transform):\n",
        "    def __call__(self, data):\n",
        "        return {\"img\": custom_gaussian_noise(data[\"img\"])}\n",
        "\n",
        "class CustomColorJitter(monai.transforms.Transform):\n",
        "    def __call__(self, data):\n",
        "        return {\"img\": custom_color_jitter(data[\"img\"])}\n",
        "\n",
        "# Define the data augmentation transforms using custom MONAI transforms\n",
        "photometric_transforms = [\n",
        "    CustomGaussianBlur(),\n",
        "    CustomGaussianNoise(),\n",
        "    CustomColorJitter(),\n",
        "]\n",
        "\n",
        "geometric_transforms = [\n",
        "    T.RandFlipd(keys=\"img\", prob=0.5, spatial_axis=0),\n",
        "    T.RandRotate90d(keys=\"img\", prob=1.0, max_k=4),\n",
        "]\n",
        "\n",
        "# Combine photometric and geometric transformations\n",
        "augmentation_transforms = photometric_transforms + geometric_transforms\n",
        "\n",
        "*augmentation_transforms,  # we Include augmentation transforms here"
      ],
      "metadata": {
        "id": "ENsVrch8ntT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Trainning and Evaluation Function**"
      ],
      "metadata": {
        "id": "q_r5k93LOgN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eval_model(model, train_loader, val_loader, criterion, optimizer, device):\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "    dice_loss = DiceLoss()\n",
        "    learning_rate = 0.001  # Set your desired learning rate value\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # optimizer = optimizer(model.parameters())\n",
        "\n",
        "    # nicializamos listas para almacenar las pérdidas y las puntuaciones de los dados\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    dice_scores = []\n",
        "\n",
        "    # Iteramos sobre cada época\n",
        "    for epoch in range(num_epochs):\n",
        "        # Ponemos el modelo en modo entrenamiento\n",
        "        model.train()\n",
        "        # Inicializamos a 0 la pérdida de entrenamiento para la época\n",
        "        train_loss = 0.0\n",
        "\n",
        "        # Iteramos sobre los lotes de datos de entrenamiento\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            images = batch[\"img\"].to(device)\n",
        "            masks = batch[\"seg\"].to(device)\n",
        "\n",
        "            # Restablecemos los gradientes del optimizador\n",
        "            optimizer.zero_grad()\n",
        "            # Generamos salidas pasando las imágenes por el modelo\n",
        "            outputs = model(images)\n",
        "            # Calculamos la pérdida entre las salidas y las máscaras\n",
        "            loss = criterion(outputs, masks)\n",
        "            # Cálculamos los gradientes por retropropagación\n",
        "            loss.backward()\n",
        "            # Actualizamos los parámetros del modelo con el optimizador\n",
        "            optimizer.step()\n",
        "\n",
        "            # Añadimos la pérdida del lote actual a la pérdida de entrenamiento\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Calculamos la pérdida media de entrenamiento para la época\n",
        "        train_loss /= len(train_loader)\n",
        "        # Añadimos la pérdida a la lista vacia train_losses\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "\n",
        "        # Ahora ponemos el modelo en modo evaluación\n",
        "        model.eval()\n",
        "        # Inicializamos la pérdida de validación para la época a 0\n",
        "        val_loss = 0.0\n",
        "        # Creamos un objeto DiceMetric con los parámetros especificados\n",
        "        dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "\n",
        "        # Desactivamos el cálculo del gradiente durante la validación\n",
        "        with torch.no_grad():\n",
        "            # Iteramos sobre los lotes de datos de validación\n",
        "            for i, batch in enumerate(val_loader):\n",
        "                images = batch[\"img\"].to(device)\n",
        "                masks = batch[\"seg\"].to(device)\n",
        "\n",
        "                # Generamos las salidas pasando las imágenes por el modelo\n",
        "                outputs = model(images)\n",
        "                # Calculamos la pérdida entre las salidas y las máscaras\n",
        "                val_loss += criterion(outputs, masks).item()\n",
        "\n",
        "                # Actualizamos la métrica de los dados comparando las salidas y las máscaras\n",
        "                dice_metric(outputs, masks)\n",
        "\n",
        "        # Calculamos la pérdida media de validación para la época\n",
        "        val_loss /= len(val_loader)\n",
        "        # Añadimos la pérdida de validación a la lista\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Calculamos la dice score\n",
        "        dice_score = dice_metric.aggregate().item()\n",
        "        # Añadimos la dice score a la lista\n",
        "        dice_scores.append(dice_score)\n",
        "\n",
        "        # Imprimimos la pérdida de entrenamiento, la pérdida de validación y la puntuación dada para la época\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Dice Score: {dice_score:.4f}\")\n",
        "\n",
        "    # Devolvemos las listas de pérdidas del training, pérdidas de la validación y los dice scores.\n",
        "    return train_losses, val_losses, dice_scores\n"
      ],
      "metadata": {
        "id": "6tu3TRpgOkAn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training the DeepLabV3+ Model**"
      ],
      "metadata": {
        "id": "prlP-8NPOqBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model configurations\n",
        "model_configs = [\n",
        "    {\"name\": \"DeepLabV3\", \"model\": smp.DeepLabV3, \"params\": {\"encoder_name\": \"resnet34\", \"in_channels\": 3, \"classes\": 3}},\n",
        "]\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    \"num_epochs\": [300],  # Train for 300 epochs.\n",
        "    \"optimizer\": [optim.Adam],  # Use Adam optimizer\n",
        "    \"lr\": [5e-5, 2e-3],  # Learning rate range: [5e-5, 2e-3]\n",
        "    \"loss\": [monai.losses.DiceLoss],  # Uso DiceLoss para DeepLabV3+\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame to store the results\n",
        "results_df = pd.DataFrame()\n",
        "\n",
        "# Iteramos sobre las configuraciones del modelo y el parameter grid, entrenamos y evaluamos cada modelo y almacenamos los resultados en el DataFrame.\n",
        "for model_config in model_configs:\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        # Obtenemos el nombre del modelo y creamos una instancia del modelo con los parámetros que hemos especificado.\n",
        "        model_name = model_config[\"name\"]\n",
        "        model = model_config[\"model\"](**model_config[\"params\"])\n",
        "        # Obtenga el número de épocas, el optimizador y la función de pérdida del parameter grid\n",
        "        num_epochs = params[\"num_epochs\"]\n",
        "        optimizer = params[\"optimizer\"]\n",
        "        learning_rate = params[\"lr\"]\n",
        "        loss = params[\"loss\"]()\n",
        "\n",
        "        # Move the model to the appropriate device\n",
        "        model.to(device)\n",
        "\n",
        "        # Define the Adam optimizer with the specified learning rate\n",
        "        optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Train and evaluate the model using the train_eval_model function\n",
        "        train_losses, val_losses, dice_scores = train_eval_model(\n",
        "            model, train_dloader, val_dloader, loss, optimizer, device\n",
        "        )\n",
        "\n",
        "        # Iterate over each epoch and store the results in the DataFrame\n",
        "        for epoch in range(num_epochs):\n",
        "            results_df = results_df.append(\n",
        "                {\n",
        "                    \"Model\": model_name,\n",
        "                    \"Num Epochs\": num_epochs,\n",
        "                    \"Optimizer\": \"Adam\",\n",
        "                    \"Loss\": loss.__class__.__name__,\n",
        "                    \"Train Loss\": train_losses[epoch],\n",
        "                    \"Val Loss\": val_losses[epoch],\n",
        "                    \"Dice Score\": dice_scores[epoch],\n",
        "                },\n",
        "                ignore_index=True,\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayMG90kEOtHz",
        "outputId": "ed7ca580-b033-4c93-ec12-0e13cc596e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300: Train Loss: 0.4964, Val Loss: 0.4567, Dice Score: 0.6242\n",
            "Epoch 2/300: Train Loss: 0.4457, Val Loss: 0.4443, Dice Score: 0.6576\n",
            "Epoch 3/300: Train Loss: 0.4313, Val Loss: 0.4162, Dice Score: 0.6019\n",
            "Epoch 4/300: Train Loss: 0.4089, Val Loss: 0.4004, Dice Score: 0.6345\n",
            "Epoch 5/300: Train Loss: 0.3786, Val Loss: 0.3700, Dice Score: 0.6234\n",
            "Epoch 6/300: Train Loss: 0.3664, Val Loss: 0.3202, Dice Score: 0.6243\n",
            "Epoch 7/300: Train Loss: 0.4123, Val Loss: 0.4011, Dice Score: 0.6365\n",
            "Epoch 8/300: Train Loss: 0.3970, Val Loss: 0.4218, Dice Score: 0.6300\n",
            "Epoch 9/300: Train Loss: 0.3964, Val Loss: 0.3843, Dice Score: 0.6123\n",
            "Epoch 10/300: Train Loss: 0.3852, Val Loss: 0.3794, Dice Score: 0.6014\n",
            "Epoch 11/300: Train Loss: 0.3832, Val Loss: 0.3818, Dice Score: 0.6454\n",
            "Epoch 12/300: Train Loss: 0.3805, Val Loss: 0.3751, Dice Score: 0.6295\n",
            "Epoch 13/300: Train Loss: 0.3739, Val Loss: 0.3604, Dice Score: 0.6447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results with all rows displayed\n",
        "pd.set_option(\"display.max_rows\", None)  # Set the maximum number of rows to display as None (show all rows)\n",
        "\n",
        "# Print the results DataFrame\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbYiWwqVZptX",
        "outputId": "20381e4e-4c69-42a0-88a8-dac81fb12929"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos el modelo\n",
        "import joblib\n",
        "filename = 'Ocelot_Base_model.sav'\n",
        "joblib.dump(model, filename)"
      ],
      "metadata": {
        "id": "X2XyL493ZsOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training loss over epochs\n",
        "plt.figure()\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Train Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(f\"{model_name} - Training Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ne398KCOZuoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test of the DeepLabV3+ Model - ocelot**"
      ],
      "metadata": {
        "id": "pr2L9hFRXe2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "criterion = DiceLoss(include_background=True, reduction=\"mean\")\n",
        "test_loss = 0.0\n",
        "\n",
        "# Initialize variables to store the predicted and ground truth masks\n",
        "pred_masks = []\n",
        "gt_masks = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_dloader:\n",
        "        images = batch[\"img\"].to(device)\n",
        "        masks = batch[\"seg\"].to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        test_loss += criterion(outputs, masks).item()\n",
        "\n",
        "        pred_masks.extend(torch.argmax(outputs, dim=1).detach().cpu().numpy())\n",
        "        gt_masks.extend(torch.argmax(masks, dim=1).detach().cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_dloader)\n",
        "\n",
        "# Convert the predicted and ground truth masks to binary matrices\n",
        "pred_masks = np.array(pred_masks)  # y_pred\n",
        "gt_masks = np.array(gt_masks)  # y_true\n",
        "pred_masks = np.eye(num_classes)[pred_masks]  # one-hot encoding\n",
        "gt_masks = np.eye(num_classes)[gt_masks]  # one-hot encoding\n",
        "\n",
        "# Calculate the Dice coefficient\n",
        "intersection = np.sum(pred_masks * gt_masks, axis=(1, 2, 3))\n",
        "sum_u = np.sum(pred_masks, axis=(1, 2, 3)) + np.sum(gt_masks, axis=(1, 2, 3))\n",
        "dice_coefficient = (2.0 * intersection) / (sum_u + 1e-7)\n",
        "average_dice_coefficient = np.mean(dice_coefficient)\n",
        "\n",
        "# Calculate Intersection over Union (IoU)\n",
        "union = sum_u - intersection\n",
        "iou = intersection / (union + 1e-7)\n",
        "average_iou = np.mean(iou)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "true_positive = np.sum(pred_masks * gt_masks, axis=(1, 2, 3))\n",
        "false_positive = np.sum(pred_masks * (1 - gt_masks), axis=(1, 2, 3))\n",
        "false_negative = np.sum((1 - pred_masks) * gt_masks, axis=(1, 2, 3))\n",
        "precision = true_positive / (true_positive + false_positive + 1e-7)\n",
        "recall = true_positive / (true_positive + false_negative + 1e-7)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
        "average_precision = np.mean(precision)\n",
        "average_recall = np.mean(recall)\n",
        "average_f1 = np.mean(f1_score)\n",
        "\n",
        "# Calculate Pixel Accuracy\n",
        "correct_pixels = np.sum(np.all(pred_masks == gt_masks, axis=1), axis=(1, 2))\n",
        "total_pixels = np.prod(pred_masks.shape[1:])\n",
        "pixel_accuracy = correct_pixels / total_pixels\n",
        "average_pixel_accuracy = np.mean(pixel_accuracy)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) and Mean Squared Error (MSE)\n",
        "mae = np.mean(np.abs(pred_masks - gt_masks))\n",
        "mse = np.mean(np.square(pred_masks - gt_masks))\n",
        "\n",
        "# Print all evaluation metrics\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Average Dice Coefficient: {average_dice_coefficient:.4f}\")\n",
        "print(f\"Average IoU: {average_iou:.4f}\")\n",
        "print(f\"Average Precision: {average_precision:.4f}\")\n",
        "print(f\"Average Recall: {average_recall:.4f}\")\n",
        "print(f\"Average F1-Score: {average_f1:.4f}\")\n",
        "print(f\"Average Pixel Accuracy: {average_pixel_accuracy:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")"
      ],
      "metadata": {
        "id": "C8NFU2gKXlQ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}